--- 
title: "EigenGWAS theory and application"
author: "Guo-Bo Chen [chen.guobo@foxmail.com]"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
description: "EigenGWAS Project."
---

# EigenGWAS basis {#ch:basis}

This project is dedicated to <font color="navy">`EigenGWAS`</font>, a linear model analysis approach for eigenvectors on genomic data, which can be represented as $\mathbf{X}$ the $n \times m$ genotype matrix. Without loss of generality, $x_{jl}$ is a biallic code for the $i^{th}$ individual at the $l^{th}$ locus. The data matrix $\mathbf{X}$ can be generated from genotyping chips, NGS, or GBS.

## Genetic relatedness matrix $\mathbf{G}$

We can construct the $n\times$ genetic relatedness matrix as
$\mathbf{X}$ the $n\times m$ genotype matrix. We can construct the $n\times$ genetic relatedness matrix as

$$\mathbf{G}=\tilde{\mathbf{X}}\tilde{\mathbf{X}}^T$$
in which $\tilde{\mathbf{X}}$ is the scaled form of $\mathbf{X}$
However, upon the mating type of the species, $\mathbf{G}$ should be constructly differently. For a random mating population, $x_l$ is scaled as $\tilde{x}_l=\frac{x_l-2p_l}{\sqrt{2p_lq_l}}$, whereas for inbred population, $\tilde{x}_l=\frac{x_l-2p_l}{\sqrt{4p_lq_l}}$. $q_l$ equals $1-p_l$.

So for a pair of individuals $i$ and $j$, 

\begin{equation}
G_{ij}=\frac{1}{\tilde{m}}\sum_l^{\tilde{m}}\frac{(x_{il}-2p_l)(x_{jl}-2p_l)}{2(1+F)p_lq_l} (\#eq:G)
\end{equation}

in which $\tilde{m}$ is the number of genotyped loci at both individal $i$ and $j$, and $F$ the inbreeding coefficient takes value of 0 for random mating population and 1 for inbred population.


### Statistical properties of $\mathbf{G}$

Given $\mathbf{G}$, we can define two population parameters, $n_e$, the effective population size, and $m_e$, the effective number of markers.

Let $\mathbf{G}_o$ denote the off diagonal elements of $\mathbf{G}$, then we have 

\begin{equation}
n_e=\frac{-1}{mean(\mathbf{G}_o)} (\#eq:Ne)
\end{equation}
$n_e$ reflects true relatedness between any pair of samples; 

\begin{equation}
m_e=\frac{1}{Var(\mathbf{G}_o)}  (\#eq:Me1)
\end{equation}
The ratio between $\frac{m_e}{m}$ reflects the average linkage disequilibrium between the any pair of markers, and alternatively $m_e$ can be expressed as

\begin{equation}
m_e=\frac{\sum_{l_1=1}^m\sum_{l_2=1}^m\rho_{l_1l_2}^2}{m^2}=\bar{\rho}^2 (\#eq:Me2)
\end{equation}

in which $\rho_{l_1l_2}$ is Pearson's correlation between a pair of SNPs. It is an important parameter to describe the evolutionary process of a population of study.

## EigenGWAS linear model
Given [eigenanalysis](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors) of $\mathbf{X}$, we have $\mathbf{E}$ and $\mathbf{\Lambda}$, in which $\mathbf{\Lambda}$ is an $n \times n$ diagonal matrix for eigenvalues and $\mathbf{E}$ is an $n \times n$  matrix for the eigenvectors. $\mathbf{E}_k$ is the eigenvector associated with the $k^{th}$ largest eigenvalue. Regressing $\mathbf{E}_k$ against each marker, we have the model below

\begin{equation}
\mathbf{E}_k=a+\beta_j\mathbf{x}_i+e (\#eq:EG-mod)
\end{equation}

It consequently generates $m$ estimates of $\beta$, $\sigma_j$, and their corresponding $p$ values. Given the $m$ $p$ values, the conventional 
Manhattan plot can be made.

In particular, the one-degree-of-freedom $\chi^2_1$ has approximation as

\begin{equation}
4\frac{\color{red}{n_1}\color{blue}{n_2}}{n}\frac{(\color{red}{p_{1,l}}-\color{blue}{p_{2,l}})^2}{2\bar{p}_l\bar{q}_l}=4n\omega_1 \omega_2 F_{st}^N=nF_{st}^W (\#eq:EG-chi)
\end{equation}

in which $\color{red}{n_1}$ and $\color{blue}{n_2}$ are the numbers of samples at the left and right side of "0" on the eigenvector, see the figure below. $\color{red}{p_{1,l}}$ and $\color{blue}{p_{2,l}}$ are frequencies of the reference allele in two subgroups, respectively. $\bar{p_l}$ is the allele frequency of the reference allele. $F_{st}^N=\frac{(\color{red}{p_{1,l}}-\color{blue}{p_{2,l}})^2}{2\bar{p}_l\bar{q}_l}$ and $F_{st}^W=2\frac{\sum_{g=1}^2\omega_g(p_{g,l}-{\bar p_l})^2}{\bar{p}_l\bar{q}_l}$.

```{r, eigen, collapse=TRUE, tidy=TRUE}
set.seed(2018)
layout(matrix(1:4, 2, 2))
freq=runif(1000, 0.1, 0.9)
X=matrix(0, 100, length(freq))
for(i in 1:length(freq)) {
  X[,i]=rbinom(nrow(X), 2, freq[i])
}
print(dim(X))
plot(freq, colMeans(X)/2, xlab="Simulated frequency", ylab="Estimated frequency", bty='n', pch=16, cex=0.5)
abline(a=0, b=1, col="red", lty=2)

Xs=apply(X, 2, scale)
G=Xs %*% t(Xs)/ncol(X)
Ne=-1/mean(G[col(G)<row(G)])
Me=1/var(G[col(G)<row(G)])
print(paste("Ne=", Ne, "Me=", Me, "given N=", nrow(Xs), "and M=", ncol(Xs)))
hist(G[col(G)<row(G)], main="GRM", xlab="Relatedness", breaks = 25)
legend("topright", legend = c(paste0("Ne=", format(Ne, digits = 2)), paste0("Me=", format(Me, digits = 2)) ), bty = 'n')

#Eigen
eigenG=eigen(G)
barplot(eigenG$values, main="Eigenvalues")
plot(eigenG$vectors[,1], eigenG$vectors[,2], xlab="Eigen 1", ylab="Eigen 2", bty='n', main="Eigenspace", pch=16, cex=0.5, col=ifelse(eigenG$vectors[,1]>0, "red", "blue"))
abline(v=0, col="grey", lty=2)
```

### $\lambda_{GC}$ correction
We can define $\lambda_{GC}=\chi^2_{1,median(p)}/\chi^2_{1,0.5}$, in which $\chi^2_{1,0.5}=0.455$. We further use subscript $k$ to denote $\lambda_{GC_k}$ the one that is estimated from the EigenGWAS analysis of $\mathbf{E}_k$, as shown \@ref(eq:EG-mod).

After technical correction, correspondingly 

\begin{equation}
\tilde\chi^2_1=\chi^2_1/\lambda_{GC} (\#eq:EG-chi-adj)
\end{equation}

a correction of the test statistic compared to its original form. This correction has several implications

- Statistically, as \@ref(eq:EG-mod) has its response variable from $\mathbf{X}$, the correctin removes its overfitting.

- Genetically, it corrects for genetic drift such as for $\mathbf{E}_1$. Here quantity of the genetic drift is measured by the median value of the $\chi^2_1$ values observed.


```{r, gc, collapse=TRUE}
Chi=rchisq(10000, 1, ncp=0.2)
layout(matrix(1:2, 1, 2))
qqplot(main="Raw", rchisq(1000,1), Chi, bty="n", xlab=expression(paste("Theoretical ",chi[1]^2)), ylab=expression(paste("Observed ",chi[1]^2)), pch=16, cex=0.5)
abline(a=0, b=1, col="red", lty=2)
gc=median(Chi)/qchisq(0.5, 1, lower.tail = F)
ChiGC=Chi/gc
qqplot(main="After correction", rchisq(1000,1), ChiGC, bty="n", xlab=expression(paste("Theoretical ",chi[1]^2)), ylab=expression(paste("Observed ",chi[1]^2)), pch=16, cex=0.5)
abline(a=0, b=1, col="red", lty=2)
```

## Connection to SVD
Singular value decomposition, [see SVD wiki for more details](https://en.wikipedia.org/wiki/Singular_value_decomposition), can decompose the matrix $\mathbf{X}$ into
\begin{equation}
\mathbf{X}=\mathbf{U\Sigma V} (\#eq:SVD)
\end{equation}
in which

- $\mathbf{U}$ is an $n\times n$ unitary matrix, corresponding to individual-level loading for each sample,

- $\mathbf{\Sigma}$ an $n\times m$ diagonal matrix, 

- and $\mathbf{V}$ an $m\times m$ unitary matrix, corresponding to SNP-level loading.

Due to the transformation between $\mathbf{U}$ and $\mathbf{V}$, it has 
\begin{equation}
\mathbf{U}=\mathbf{\tilde{X}V\Sigma}^{-1} (\#eq:svd)
\end{equation}
The right side can be unfolded as $\frac{\sqrt{m}}{\sqrt{\Sigma_k}}\mathbf{x}_l\mathbf{v}_k$, follows $N(0,1)$, and taking square of it leads to 
\begin{equation}
(\frac{\sqrt{m}}{\sqrt{\Sigma_k}}\mathbf{\tilde{x}}_l\mathbf{v}_k)^2 \sim \chi^2_1 (\#eq:chi-svd)
\end{equation}

It brings out an interesting comparison between \@ref(eq:EG-chi-adj) and \@ref(eq:svd).
The subtle difference, for instance for $E_1$, in their correction using $\lambda_{GC}$ and $\Sigma_1$. When the population divergency is due to genetic drift and a small proportion of loci are under selection,  $\Sigma_1 \gt \lambda_{GC}$. It is because $\Sigma_1$ is the mean of the $\chi^2_1$ from \@ref(eq:EG-chi), but $\lambda_{GC}$ is the median of it. Given a population under selection, such as selection sweep, it does have $\lambda_{GC} \gt \Sigma_1$, as demonstrated in [simulation](http://rpubs.com/gc5k/EigenGWAScore).

So, using linear model system such as <font color="navy">`EigenGWAS`</font> gives more flexibility, as well as improved statistical power comparing with SVD transformation.

However, in this transformation, eigenvalue is involved, as would be show. It will reduce the statistical power for <font color="navy">`EigenGWAS`</font>.

### Threshold for EigenGWAS
As shown above, <font color="navy">`EigenGWAS`</font> is a linear model framework nearly identical to the conventional GWAS, and Bonferroni correction, such as $\alpha/m$, can be used to set the threshold at the significance level $\alpha$, such as $\alpha=0.05$.

## Classic mechanic intepretation
The <font color="navy">`EigenGWAS`</font> model resembles the Newtown's first and the second law for classical mechanics. The first law states that 

>"In an inertial frame of reference, an object either remains at rest or continues to move at a constant velocity, unless acted upon by a force."

Analogously, in population genetics, it can be seemed as genetic drift that is constantly driving the a pair of population apart from each other, and its velocity can be quantified by a binomial distribution as $\frac{pq}{\tilde{n}_e}$.

>"In an inertial frame of reference, the vector sum of the forces $F$ on an object is equal to the mass m of that object multiplied by the acceleration a of the object: $F = ma$."

Analogously, the selection can drive a genomic region run against its reference population at a velocity greater than $\frac{pq}{\tilde{n}_e}$.
